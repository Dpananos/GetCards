{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get Flashcards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy \n",
    "import wget\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill these in\n",
    "consumer_key = ''\n",
    "consumer_secret =''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Get 200 of Chris' tweet\n",
    "tweets = api.user_timeline(screen_name = 'chrisalbon', \n",
    "                           count = 200, \n",
    "                           include_rts = False, \n",
    "                           excludereplies = True)\n",
    "\n",
    "#200 isn't enough.  Keep getting tweets until we can't get anymore\n",
    "\n",
    "last_id = tweets[-1].id\n",
    " \n",
    "while (True):\n",
    "    more_tweets = api.user_timeline(screen_name='chrisalbon',\n",
    "                                count=200,\n",
    "                                include_rts=False,\n",
    "                                exclude_replies=True,\n",
    "                                max_id=last_id-1)\n",
    "                                    \n",
    "    # There are no more tweets\n",
    "    if (len(more_tweets) == 0):\n",
    "          break\n",
    "    else:\n",
    "        last_id = more_tweets[-1].id-1\n",
    "        tweets += more_tweets\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chris stopped using a hashtag and started linking a URL\n",
    "def has_ML_url(s):\n",
    "    urls = s.entities.get('urls')\n",
    "    if urls:\n",
    "        return(urls[0].get('display_url') == 'machinelearningflashcards.com')\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter by those containing machinelearningflashcards.com\n",
    "card_tweets = [tweet for tweet in tweets if has_ML_url(tweet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_files = dict()\n",
    "for status in card_tweets:\n",
    "    title = status.text.split(' http')[0]\n",
    "    media = status.entities.get('media', [])\n",
    "    if(len(media) > 0 and media[0]['type']=='photo' ):  #if tweet has media and media is photo\n",
    "        media_files[title] = media[0]['media_url']  #get me the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('ml-cards', exist_ok=True) #make a directory to store the photos in\n",
    "\n",
    "for title, url in media_files.items():\n",
    "   wget.download(url, out = \"ml-cards/{}.png\".format(title)) #get the photos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
